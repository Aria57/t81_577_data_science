{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Vectorization?\n",
    "\n",
    "\n",
    "Vectorization in Python can be understood in a simple way as an art of removing explicit for loops in a code. In Numpy, it is a way of expressing operations as occurring on entire arrays rather than their individual elements.In general, vectorized array operations result in two or more orders of magnitude faster than their pure Python equivalents. Data scientists frequently find themseleves working on a very big data set. Such marginal gain in speed due to vectorization can turn out to be a huge gain while prototyping a model with big data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume a problem similar to multiple regression:\n",
    "    \n",
    "  ```python\n",
    "    Y = B.T * X + beta0\n",
    "  ```\n",
    "  where,\n",
    "  X is matrix (MxN) of N columns (features) and M rows (observations). B.T is the transpose of the estimated coefficients  of the models (N-dimensional vector) and  beta0 being the intercept.\n",
    "  \n",
    "  In a non vectorized implementation, to predict the values of Y from X and estimated coefficients, we might write a code somthing like this:\n",
    "  ```python\n",
    "  \n",
    "  for i in range(X.shape[0]):\n",
    "    y[i] = 0\n",
    "    for j in range(X.shape[1]):\n",
    "      y[i] += B[j]* X[j]\n",
    "      y[i] += beta0\n",
    "  ```\n",
    "  The above code in practice is going to be very slow when \n",
    "  \n",
    "  In contrast, in a vectorized implementation in Numpy, we can directly compute y using dot product between `_B_` and `_X_` as following:\n",
    "  \n",
    "  ```python\n",
    "  y = np.dot(B,X) + beta0\n",
    "    ```\n",
    "  \n",
    "  Lets determine the computational time difference between the two implementations by working out with an example as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for non-vectorized implementation: 5.928127288818359 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "X = np.random.rand(1000000,5)\n",
    "beta = np.random.rand(5).T\n",
    "beta0 = np.random.rand(1)\n",
    "y = np.zeros(1000000,)\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        y[i] += beta[j]* X[i,j]\n",
    "    y[i] += beta0\n",
    "toc = time.time()\n",
    "print('Time taken for non-vectorized implementation: {} s'.format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2053305  1.38900838 1.57590593 ... 1.40615506 1.277243   1.51182592]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for non-vectorized implementation: 0.038630008697509766 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "Y = np.dot(X,beta) + beta0\n",
    "toc = time.time()\n",
    "print('Time taken for non-vectorized implementation: {} s'.format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2053305  1.38900838 1.57590593 ... 1.40615506 1.277243   1.51182592]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the vectorized implemetation was almost 400 times faster than non-vectorized counterpart.Hence,  one should always get rid of  explicit for-loops over large array of data when whenever computational efficiency is important.\n",
    "\n",
    "Apart from the illustrated gain in computational speed, vectorization implementation is also amenable to parrallel computation, and hence can improve the computational performace even by higher order of magnitude depending upon the number os cores used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
